{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Generation with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pickle\n",
    "from music21 import converter, instrument, stream, note, chord\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Activation, Bidirectional, LayerNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notes():\n",
    "    \"\"\" Get all the notes and chords from the midi files in the ./full_set_beethoven_mozart directory. Call BEFORE train \"\"\"\n",
    "    notes = []\n",
    "    durations = []\n",
    "    files = \"samples/*.mid\"\n",
    "\n",
    "    for file in glob.glob(files):\n",
    "        midi = None\n",
    "        try:\n",
    "            midi = converter.parse(file)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        print(\"Parsing %s\" % file)\n",
    "\n",
    "        notes_to_parse = None\n",
    "\n",
    "        try: # file has instrument parts\n",
    "            s2 = instrument.partitionByInstrument(midi) #Change to only grab the piano???\n",
    "            notes_to_parse = s2.parts[0].recurse() \n",
    "        except: # file has notes in a flat structure\n",
    "            notes_to_parse = midi.flat.notes\n",
    "\n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch) + \" \" +  str(element.quarterLength))\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder) + \" \" + str(element.quarterLength))\n",
    "            elif isinstance(element, note.Rest):\n",
    "                notes.append(str(element.name)  + \" \" + str(element.quarterLength))\n",
    "\n",
    "    pickle.dump(notes, open('data/notes.p', 'wb'))\n",
    "\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences(notes, n_vocab):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "    sequence_length = 16\n",
    "\n",
    "    # get all pitch names\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "\n",
    "     # create a dictionary to map pitches to integers\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "\n",
    "    # create input sequences and the corresponding outputs\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        network_output.append(note_to_int[sequence_out])\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    # normalize input\n",
    "    network_input = network_input / float(n_vocab)\n",
    "\n",
    "    network_output = to_categorical(network_output)\n",
    "\n",
    "    return (network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network(network_input, n_vocab):\n",
    "    \"\"\" create the structure of the neural network \"\"\"\n",
    "    hidden_layers = 256\n",
    "    dropout = 0.4\n",
    "    \n",
    "    \"\"\" Initializing model \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    \"\"\" Adding LSTM Layers to Model \"\"\"\n",
    "    model.add(\n",
    "        Bidirectional(\n",
    "            LSTM(\n",
    "                hidden_layers,\n",
    "                dropout=dropout,\n",
    "                return_sequences=True\n",
    "            ),\n",
    "            input_shape=(network_input.shape[1], network_input.shape[2])\n",
    "        )\n",
    "    )\n",
    "    model.add(LayerNormalization())\n",
    "    model.add(\n",
    "        Bidirectional(\n",
    "            LSTM(\n",
    "                hidden_layers,\n",
    "                dropout=dropout,\n",
    "                return_sequences=True\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    model.add(LayerNormalization())\n",
    "    model.add(\n",
    "        Bidirectional(\n",
    "            LSTM(\n",
    "                hidden_layers,\n",
    "                dropout=dropout\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    model.add(LayerNormalization())\n",
    "    \n",
    "    \"\"\" Add other layers after LSTM \"\"\"\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(hidden_layers))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(LayerNormalization())\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(clipnorm=1.0))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(load_notes=False, to_load_model=False, learning_rate=None):\n",
    "    \"\"\" Train a Neural Network to generate music \"\"\"\n",
    "    notes = None\n",
    "    model = None\n",
    "\n",
    "    if load_notes:\n",
    "        notes = pickle.load(open('data/notes.p', 'rb'))\n",
    "    else:\n",
    "        notes = get_notes()\n",
    "    \n",
    "    n_vocab = len(set(notes))\n",
    "    network_input, network_output = prepare_sequences(notes, n_vocab)\n",
    "\n",
    "    if to_load_model:\n",
    "        model = load_model('weights.hdf5')\n",
    "    else:\n",
    "        model = create_network(network_input, n_vocab)\n",
    "\n",
    "    if learning_rate != None:\n",
    "        K.set_value(model.optimizer.learning_rate, learning_rate)\n",
    "\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        'weights.hdf5',\n",
    "        monitor='loss',\n",
    "        save_best_only=True,\n",
    "        mode='min'\n",
    "    )\n",
    "\n",
    "    callbacks_list = [checkpoint]\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    model.fit(\n",
    "        x=network_input,\n",
    "        y=network_output,\n",
    "        batch_size=1024,\n",
    "        epochs=3000,\n",
    "        callbacks=callbacks_list\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional (Bidirectional (None, 16, 512)           528384    \n",
      "_________________________________________________________________\n",
      "layer_normalization (LayerNo (None, 16, 512)           1024      \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 16, 512)           1574912   \n",
      "_________________________________________________________________\n",
      "layer_normalization_1 (Layer (None, 16, 512)           1024      \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 512)               1574912   \n",
      "_________________________________________________________________\n",
      "layer_normalization_2 (Layer (None, 512)               1024      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "layer_normalization_3 (Layer (None, 256)               512       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1699)              436643    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1699)              0         \n",
      "=================================================================\n",
      "Total params: 4,249,763\n",
      "Trainable params: 4,249,763\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3000\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.4131\n",
      "Epoch 2/3000\n",
      "52/52 [==============================] - 6s 111ms/step - loss: 0.4100\n",
      "Epoch 3/3000\n",
      "52/52 [==============================] - 6s 108ms/step - loss: 0.4126\n",
      "Epoch 4/3000\n",
      "52/52 [==============================] - 6s 108ms/step - loss: 0.4121\n",
      "Epoch 5/3000\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.4033\n",
      "Epoch 6/3000\n",
      "52/52 [==============================] - 6s 109ms/step - loss: 0.4044\n",
      "Epoch 7/3000\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.3995\n",
      "Epoch 8/3000\n",
      "52/52 [==============================] - 6s 109ms/step - loss: 0.4059\n",
      "Epoch 9/3000\n",
      "52/52 [==============================] - 6s 109ms/step - loss: 0.4081\n",
      "Epoch 10/3000\n",
      "52/52 [==============================] - 6s 110ms/step - loss: 0.4186\n",
      "Epoch 11/3000\n",
      "52/52 [==============================] - 6s 109ms/step - loss: 0.4085\n",
      "Epoch 12/3000\n",
      "52/52 [==============================] - 6s 109ms/step - loss: 0.4115\n",
      "Epoch 13/3000\n",
      "52/52 [==============================] - 6s 110ms/step - loss: 0.4005\n",
      "Epoch 14/3000\n",
      "52/52 [==============================] - 6s 110ms/step - loss: 0.4191\n",
      "Epoch 15/3000\n",
      "52/52 [==============================] - 6s 110ms/step - loss: 0.4059\n",
      "Epoch 16/3000\n",
      "52/52 [==============================] - 6s 110ms/step - loss: 0.4029\n",
      "Epoch 17/3000\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.4131\n",
      "Epoch 18/3000\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.4063\n",
      "Epoch 19/3000\n",
      "52/52 [==============================] - 6s 111ms/step - loss: 0.4060\n",
      "Epoch 20/3000\n",
      "52/52 [==============================] - 6s 111ms/step - loss: 0.4059\n",
      "Epoch 21/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3976\n",
      "Epoch 22/3000\n",
      "52/52 [==============================] - 6s 111ms/step - loss: 0.4046\n",
      "Epoch 23/3000\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.4014\n",
      "Epoch 24/3000\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.4005\n",
      "Epoch 25/3000\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.4083\n",
      "Epoch 26/3000\n",
      "52/52 [==============================] - 6s 111ms/step - loss: 0.4084\n",
      "Epoch 27/3000\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.4032\n",
      "Epoch 28/3000\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.4170\n",
      "Epoch 29/3000\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.4039\n",
      "Epoch 30/3000\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.4095\n",
      "Epoch 31/3000\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.4067\n",
      "Epoch 32/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4070\n",
      "Epoch 33/3000\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.4095\n",
      "Epoch 34/3000\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.4173\n",
      "Epoch 35/3000\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.4035\n",
      "Epoch 36/3000\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.4018\n",
      "Epoch 37/3000\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.4101\n",
      "Epoch 38/3000\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.4044\n",
      "Epoch 39/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4105\n",
      "Epoch 40/3000\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.4129\n",
      "Epoch 41/3000\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.4093\n",
      "Epoch 42/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4058\n",
      "Epoch 43/3000\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.4195\n",
      "Epoch 44/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4084\n",
      "Epoch 45/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4051\n",
      "Epoch 46/3000\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.4070\n",
      "Epoch 47/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4055\n",
      "Epoch 48/3000\n",
      "52/52 [==============================] - 6s 117ms/step - loss: 0.3955\n",
      "Epoch 49/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4063\n",
      "Epoch 50/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4089\n",
      "Epoch 51/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4110\n",
      "Epoch 52/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4037\n",
      "Epoch 53/3000\n",
      "52/52 [==============================] - 6s 112ms/step - loss: 0.4025\n",
      "Epoch 54/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4088\n",
      "Epoch 55/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4086\n",
      "Epoch 56/3000\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.4083\n",
      "Epoch 57/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.4034\n",
      "Epoch 58/3000\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.4064\n",
      "Epoch 59/3000\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.4039\n",
      "Epoch 60/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.4027\n",
      "Epoch 61/3000\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.4079\n",
      "Epoch 62/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3994\n",
      "Epoch 63/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4095\n",
      "Epoch 64/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4074\n",
      "Epoch 65/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4026\n",
      "Epoch 66/3000\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.3979\n",
      "Epoch 67/3000\n",
      "52/52 [==============================] - 6s 119ms/step - loss: 0.3934\n",
      "Epoch 68/3000\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.4051\n",
      "Epoch 69/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4023\n",
      "Epoch 70/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4023\n",
      "Epoch 71/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4072\n",
      "Epoch 72/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4008\n",
      "Epoch 73/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.4083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4041\n",
      "Epoch 75/3000\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.4032\n",
      "Epoch 76/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4140\n",
      "Epoch 77/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3993\n",
      "Epoch 78/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3999\n",
      "Epoch 79/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.4013\n",
      "Epoch 80/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4015\n",
      "Epoch 81/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4015\n",
      "Epoch 82/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4020\n",
      "Epoch 83/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4068\n",
      "Epoch 84/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4047\n",
      "Epoch 85/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.4093\n",
      "Epoch 86/3000\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.4028\n",
      "Epoch 87/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3999\n",
      "Epoch 88/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4043\n",
      "Epoch 89/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3989\n",
      "Epoch 90/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4082\n",
      "Epoch 91/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4057\n",
      "Epoch 92/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3942\n",
      "Epoch 93/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3983\n",
      "Epoch 94/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3983\n",
      "Epoch 95/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3961\n",
      "Epoch 96/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.4020\n",
      "Epoch 97/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4038\n",
      "Epoch 98/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4098\n",
      "Epoch 99/3000\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.4005\n",
      "Epoch 100/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4052\n",
      "Epoch 101/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4065\n",
      "Epoch 102/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4036\n",
      "Epoch 103/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4087\n",
      "Epoch 104/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.4081\n",
      "Epoch 105/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4026\n",
      "Epoch 106/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4136\n",
      "Epoch 107/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.4052\n",
      "Epoch 108/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.4084\n",
      "Epoch 109/3000\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.3989\n",
      "Epoch 110/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4064\n",
      "Epoch 111/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3957\n",
      "Epoch 112/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4043\n",
      "Epoch 113/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3949\n",
      "Epoch 114/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3993\n",
      "Epoch 115/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4085\n",
      "Epoch 116/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.4061\n",
      "Epoch 117/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4093\n",
      "Epoch 118/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4085\n",
      "Epoch 119/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4059\n",
      "Epoch 120/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4054\n",
      "Epoch 121/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.4035\n",
      "Epoch 122/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3997\n",
      "Epoch 123/3000\n",
      "52/52 [==============================] - 6s 118ms/step - loss: 0.3930\n",
      "Epoch 124/3000\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.3995\n",
      "Epoch 125/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4047\n",
      "Epoch 126/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.4126\n",
      "Epoch 127/3000\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.4093\n",
      "Epoch 128/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4099\n",
      "Epoch 129/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4017\n",
      "Epoch 130/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4039\n",
      "Epoch 131/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4044\n",
      "Epoch 132/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3976\n",
      "Epoch 133/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4015\n",
      "Epoch 134/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4086\n",
      "Epoch 135/3000\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.4040\n",
      "Epoch 136/3000\n",
      "52/52 [==============================] - 6s 120ms/step - loss: 0.3925\n",
      "Epoch 137/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4029\n",
      "Epoch 138/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4013\n",
      "Epoch 139/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4042\n",
      "Epoch 140/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4036\n",
      "Epoch 141/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3941\n",
      "Epoch 142/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4015\n",
      "Epoch 143/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3945\n",
      "Epoch 144/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3989\n",
      "Epoch 145/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3994\n",
      "Epoch 146/3000\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.3984\n",
      "Epoch 147/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.4061\n",
      "Epoch 148/3000\n",
      "52/52 [==============================] - 6s 118ms/step - loss: 0.3920\n",
      "Epoch 149/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3997\n",
      "Epoch 150/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.4097\n",
      "Epoch 151/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3984\n",
      "Epoch 152/3000\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.4004\n",
      "Epoch 153/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4114\n",
      "Epoch 154/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3994\n",
      "Epoch 155/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3960\n",
      "Epoch 156/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4080\n",
      "Epoch 157/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4042\n",
      "Epoch 158/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4098\n",
      "Epoch 159/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4033\n",
      "Epoch 160/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3925\n",
      "Epoch 161/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4027\n",
      "Epoch 162/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4071\n",
      "Epoch 163/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3992\n",
      "Epoch 164/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3991\n",
      "Epoch 165/3000\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.4080\n",
      "Epoch 166/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4054\n",
      "Epoch 167/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4017\n",
      "Epoch 168/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3984\n",
      "Epoch 169/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4052\n",
      "Epoch 170/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4090\n",
      "Epoch 171/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4095\n",
      "Epoch 172/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3985\n",
      "Epoch 173/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4089\n",
      "Epoch 174/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4152\n",
      "Epoch 175/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3975\n",
      "Epoch 176/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4011\n",
      "Epoch 177/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4001\n",
      "Epoch 178/3000\n",
      "52/52 [==============================] - 6s 119ms/step - loss: 0.3895\n",
      "Epoch 179/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3991\n",
      "Epoch 180/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4038\n",
      "Epoch 181/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4047\n",
      "Epoch 182/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4014\n",
      "Epoch 183/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4008\n",
      "Epoch 184/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3932\n",
      "Epoch 185/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4115\n",
      "Epoch 186/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3984\n",
      "Epoch 187/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3951\n",
      "Epoch 188/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3998\n",
      "Epoch 189/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3929\n",
      "Epoch 190/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3950\n",
      "Epoch 191/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4048\n",
      "Epoch 192/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.4033\n",
      "Epoch 193/3000\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.4054\n",
      "Epoch 194/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3971\n",
      "Epoch 195/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4012\n",
      "Epoch 196/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3952\n",
      "Epoch 197/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.4134\n",
      "Epoch 198/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4037\n",
      "Epoch 199/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4074\n",
      "Epoch 200/3000\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.4030\n",
      "Epoch 201/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4144\n",
      "Epoch 202/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.4005\n",
      "Epoch 203/3000\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.4077\n",
      "Epoch 204/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4009\n",
      "Epoch 205/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3952\n",
      "Epoch 206/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3975\n",
      "Epoch 207/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4018\n",
      "Epoch 208/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3967\n",
      "Epoch 209/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.4044\n",
      "Epoch 210/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3987\n",
      "Epoch 211/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3946\n",
      "Epoch 212/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4035\n",
      "Epoch 213/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.4040\n",
      "Epoch 214/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3901\n",
      "Epoch 215/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.4015\n",
      "Epoch 216/3000\n",
      "52/52 [==============================] - 6s 118ms/step - loss: 0.3884\n",
      "Epoch 217/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.4092\n",
      "Epoch 218/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4017\n",
      "Epoch 219/3000\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.4050\n",
      "Epoch 220/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4043\n",
      "Epoch 221/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.4031\n",
      "Epoch 222/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4069\n",
      "Epoch 223/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3986\n",
      "Epoch 224/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3892\n",
      "Epoch 225/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4041\n",
      "Epoch 226/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3975\n",
      "Epoch 227/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3971\n",
      "Epoch 228/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.4047\n",
      "Epoch 229/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.4076\n",
      "Epoch 230/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3940\n",
      "Epoch 231/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.4030\n",
      "Epoch 232/3000\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.3957\n",
      "Epoch 233/3000\n",
      "52/52 [==============================] - 6s 117ms/step - loss: 0.3985\n",
      "Epoch 234/3000\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.4038\n",
      "Epoch 235/3000\n",
      "52/52 [==============================] - 6s 117ms/step - loss: 0.4074\n",
      "Epoch 236/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4090\n",
      "Epoch 237/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4001\n",
      "Epoch 238/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3996\n",
      "Epoch 239/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3910\n",
      "Epoch 240/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4015\n",
      "Epoch 241/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4029\n",
      "Epoch 242/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4039\n",
      "Epoch 243/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4014\n",
      "Epoch 244/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.4000\n",
      "Epoch 245/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3941\n",
      "Epoch 246/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4069\n",
      "Epoch 247/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4012\n",
      "Epoch 248/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3966\n",
      "Epoch 249/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3995\n",
      "Epoch 250/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3940\n",
      "Epoch 251/3000\n",
      "52/52 [==============================] - 6s 117ms/step - loss: 0.3955\n",
      "Epoch 252/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4012\n",
      "Epoch 253/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3903\n",
      "Epoch 254/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4027\n",
      "Epoch 255/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3894\n",
      "Epoch 256/3000\n",
      "52/52 [==============================] - 6s 117ms/step - loss: 0.3981\n",
      "Epoch 257/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3964\n",
      "Epoch 258/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3983\n",
      "Epoch 259/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3968\n",
      "Epoch 260/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3933\n",
      "Epoch 261/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3938\n",
      "Epoch 262/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.4029\n",
      "Epoch 263/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3998\n",
      "Epoch 264/3000\n",
      "52/52 [==============================] - 6s 120ms/step - loss: 0.3874\n",
      "Epoch 265/3000\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.3891\n",
      "Epoch 266/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3971\n",
      "Epoch 267/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3925\n",
      "Epoch 268/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3984\n",
      "Epoch 269/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3972\n",
      "Epoch 270/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4039\n",
      "Epoch 271/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3999\n",
      "Epoch 272/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4023\n",
      "Epoch 273/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3976\n",
      "Epoch 274/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4004\n",
      "Epoch 275/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3990\n",
      "Epoch 276/3000\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.3983\n",
      "Epoch 277/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3891\n",
      "Epoch 278/3000\n",
      "52/52 [==============================] - 6s 117ms/step - loss: 0.3963\n",
      "Epoch 279/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3971\n",
      "Epoch 280/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3983\n",
      "Epoch 281/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4023\n",
      "Epoch 282/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3984\n",
      "Epoch 283/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3988\n",
      "Epoch 284/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3920\n",
      "Epoch 285/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3926\n",
      "Epoch 286/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3953\n",
      "Epoch 287/3000\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.3892\n",
      "Epoch 288/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3977\n",
      "Epoch 289/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3982\n",
      "Epoch 290/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3960\n",
      "Epoch 291/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3938\n",
      "Epoch 292/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3950\n",
      "Epoch 293/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.4017\n",
      "Epoch 294/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4037\n",
      "Epoch 295/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3955\n",
      "Epoch 296/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4002\n",
      "Epoch 297/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3955\n",
      "Epoch 298/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4011\n",
      "Epoch 299/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3976\n",
      "Epoch 300/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3968\n",
      "Epoch 301/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3993\n",
      "Epoch 302/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3957\n",
      "Epoch 303/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3938\n",
      "Epoch 304/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.4027\n",
      "Epoch 305/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4020\n",
      "Epoch 306/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3917\n",
      "Epoch 307/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4027\n",
      "Epoch 308/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3971\n",
      "Epoch 309/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4036\n",
      "Epoch 310/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3967\n",
      "Epoch 311/3000\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.4023\n",
      "Epoch 312/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4019\n",
      "Epoch 313/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3963\n",
      "Epoch 314/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3895\n",
      "Epoch 315/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.4025\n",
      "Epoch 316/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4016\n",
      "Epoch 317/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3965\n",
      "Epoch 318/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4008\n",
      "Epoch 319/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3965\n",
      "Epoch 320/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3985\n",
      "Epoch 321/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3941\n",
      "Epoch 322/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3929\n",
      "Epoch 323/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3935\n",
      "Epoch 324/3000\n",
      "52/52 [==============================] - 6s 118ms/step - loss: 0.3867\n",
      "Epoch 325/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3998\n",
      "Epoch 326/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3967\n",
      "Epoch 327/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3883\n",
      "Epoch 328/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3939\n",
      "Epoch 329/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4000\n",
      "Epoch 330/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3968\n",
      "Epoch 331/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3981\n",
      "Epoch 332/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4048\n",
      "Epoch 333/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3945\n",
      "Epoch 334/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4037\n",
      "Epoch 335/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4009\n",
      "Epoch 336/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3983\n",
      "Epoch 337/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3974\n",
      "Epoch 338/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3969\n",
      "Epoch 339/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3906\n",
      "Epoch 340/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3933\n",
      "Epoch 341/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3881\n",
      "Epoch 342/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3940\n",
      "Epoch 343/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3945\n",
      "Epoch 344/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3952\n",
      "Epoch 345/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.4007\n",
      "Epoch 346/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3944\n",
      "Epoch 347/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3937\n",
      "Epoch 348/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4010\n",
      "Epoch 349/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3964\n",
      "Epoch 350/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3943\n",
      "Epoch 351/3000\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.3871\n",
      "Epoch 352/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3920\n",
      "Epoch 353/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3937\n",
      "Epoch 354/3000\n",
      "52/52 [==============================] - 6s 118ms/step - loss: 0.3841\n",
      "Epoch 355/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3915\n",
      "Epoch 356/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3991\n",
      "Epoch 357/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3887\n",
      "Epoch 358/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3895\n",
      "Epoch 359/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3944\n",
      "Epoch 360/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3899\n",
      "Epoch 361/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4051\n",
      "Epoch 362/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3951\n",
      "Epoch 363/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3959\n",
      "Epoch 364/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4041\n",
      "Epoch 365/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3955\n",
      "Epoch 366/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3875\n",
      "Epoch 367/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3934\n",
      "Epoch 368/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3925\n",
      "Epoch 369/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.4023\n",
      "Epoch 370/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4003\n",
      "Epoch 371/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3941\n",
      "Epoch 372/3000\n",
      "52/52 [==============================] - 6s 119ms/step - loss: 0.3840\n",
      "Epoch 373/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3985\n",
      "Epoch 374/3000\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.3939\n",
      "Epoch 375/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.4034\n",
      "Epoch 376/3000\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.3877\n",
      "Epoch 377/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3918\n",
      "Epoch 378/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3899\n",
      "Epoch 379/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3976\n",
      "Epoch 380/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3960\n",
      "Epoch 381/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3945\n",
      "Epoch 382/3000\n",
      "52/52 [==============================] - 6s 117ms/step - loss: 0.3833\n",
      "Epoch 383/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3923\n",
      "Epoch 384/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3872\n",
      "Epoch 385/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3855\n",
      "Epoch 386/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3941\n",
      "Epoch 387/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3863\n",
      "Epoch 388/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3939\n",
      "Epoch 389/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4020\n",
      "Epoch 390/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3898\n",
      "Epoch 391/3000\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.3864\n",
      "Epoch 392/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3976\n",
      "Epoch 393/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3941\n",
      "Epoch 394/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4044\n",
      "Epoch 395/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3877\n",
      "Epoch 396/3000\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.3956\n",
      "Epoch 397/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3836\n",
      "Epoch 398/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3891\n",
      "Epoch 399/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3905\n",
      "Epoch 400/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3982\n",
      "Epoch 401/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3844\n",
      "Epoch 402/3000\n",
      "52/52 [==============================] - 6s 117ms/step - loss: 0.3863\n",
      "Epoch 403/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3898\n",
      "Epoch 404/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4009\n",
      "Epoch 405/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4013\n",
      "Epoch 406/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3958\n",
      "Epoch 407/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3880\n",
      "Epoch 408/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3957\n",
      "Epoch 409/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3947\n",
      "Epoch 410/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3972\n",
      "Epoch 411/3000\n",
      "52/52 [==============================] - 6s 117ms/step - loss: 0.3989\n",
      "Epoch 412/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3906\n",
      "Epoch 413/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3956\n",
      "Epoch 414/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.4082\n",
      "Epoch 415/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3877\n",
      "Epoch 416/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3838\n",
      "Epoch 417/3000\n",
      "52/52 [==============================] - 6s 117ms/step - loss: 0.3933\n",
      "Epoch 418/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3840\n",
      "Epoch 419/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3913\n",
      "Epoch 420/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3915\n",
      "Epoch 421/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3906\n",
      "Epoch 422/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3933\n",
      "Epoch 423/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3949\n",
      "Epoch 424/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3921\n",
      "Epoch 425/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3962\n",
      "Epoch 426/3000\n",
      "52/52 [==============================] - 6s 118ms/step - loss: 0.3975\n",
      "Epoch 427/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3865\n",
      "Epoch 428/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3899\n",
      "Epoch 429/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3965\n",
      "Epoch 430/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3957\n",
      "Epoch 431/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3944\n",
      "Epoch 432/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3872\n",
      "Epoch 433/3000\n",
      "52/52 [==============================] - 6s 117ms/step - loss: 0.3943\n",
      "Epoch 434/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3980\n",
      "Epoch 435/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3862\n",
      "Epoch 436/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3941\n",
      "Epoch 437/3000\n",
      "52/52 [==============================] - 6s 120ms/step - loss: 0.3807\n",
      "Epoch 438/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3938\n",
      "Epoch 439/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.4006\n",
      "Epoch 440/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3813\n",
      "Epoch 441/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3934\n",
      "Epoch 442/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3918\n",
      "Epoch 443/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3960\n",
      "Epoch 444/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3984\n",
      "Epoch 445/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3830\n",
      "Epoch 446/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3887\n",
      "Epoch 447/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3900\n",
      "Epoch 448/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3983\n",
      "Epoch 449/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3923\n",
      "Epoch 450/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3956\n",
      "Epoch 451/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3976\n",
      "Epoch 452/3000\n",
      "52/52 [==============================] - 6s 117ms/step - loss: 0.3939\n",
      "Epoch 453/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3979\n",
      "Epoch 454/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3901\n",
      "Epoch 455/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3991\n",
      "Epoch 456/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3978\n",
      "Epoch 457/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3887\n",
      "Epoch 458/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3853\n",
      "Epoch 459/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3870\n",
      "Epoch 460/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3831\n",
      "Epoch 461/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3901\n",
      "Epoch 462/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3920\n",
      "Epoch 463/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3857\n",
      "Epoch 464/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3862\n",
      "Epoch 465/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3824\n",
      "Epoch 466/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3956\n",
      "Epoch 467/3000\n",
      "52/52 [==============================] - 6s 117ms/step - loss: 0.3964\n",
      "Epoch 468/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3879\n",
      "Epoch 469/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3880\n",
      "Epoch 470/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3903\n",
      "Epoch 471/3000\n",
      "52/52 [==============================] - 6s 117ms/step - loss: 0.3881\n",
      "Epoch 472/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3912\n",
      "Epoch 473/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3908\n",
      "Epoch 474/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3837\n",
      "Epoch 475/3000\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.3936\n",
      "Epoch 476/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.4095\n",
      "Epoch 477/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.4019\n",
      "Epoch 478/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3925\n",
      "Epoch 479/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3940\n",
      "Epoch 480/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3876\n",
      "Epoch 481/3000\n",
      "52/52 [==============================] - 6s 117ms/step - loss: 0.3871\n",
      "Epoch 482/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3971\n",
      "Epoch 483/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3834\n",
      "Epoch 484/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3964\n",
      "Epoch 485/3000\n",
      "52/52 [==============================] - 6s 117ms/step - loss: 0.3845\n",
      "Epoch 486/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3877\n",
      "Epoch 487/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3891\n",
      "Epoch 488/3000\n",
      "52/52 [==============================] - 6s 117ms/step - loss: 0.3924\n",
      "Epoch 489/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3934\n",
      "Epoch 490/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3903\n",
      "Epoch 491/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3856\n",
      "Epoch 492/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3933\n",
      "Epoch 493/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3849\n",
      "Epoch 494/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3926\n",
      "Epoch 495/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3903\n",
      "Epoch 496/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3971\n",
      "Epoch 497/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3856\n",
      "Epoch 498/3000\n",
      "52/52 [==============================] - 6s 117ms/step - loss: 0.3889\n",
      "Epoch 499/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3885\n",
      "Epoch 500/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3880\n",
      "Epoch 501/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3956\n",
      "Epoch 502/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3901\n",
      "Epoch 503/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3950\n",
      "Epoch 504/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3939\n",
      "Epoch 505/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.4033\n",
      "Epoch 506/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3904\n",
      "Epoch 507/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3850\n",
      "Epoch 508/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3883\n",
      "Epoch 509/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3833\n",
      "Epoch 510/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3895\n",
      "Epoch 511/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3887\n",
      "Epoch 512/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3854\n",
      "Epoch 513/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3810\n",
      "Epoch 514/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3834\n",
      "Epoch 515/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3881\n",
      "Epoch 516/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3854\n",
      "Epoch 517/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3952\n",
      "Epoch 518/3000\n",
      "52/52 [==============================] - 6s 117ms/step - loss: 0.3840\n",
      "Epoch 519/3000\n",
      "52/52 [==============================] - 6s 119ms/step - loss: 0.3789\n",
      "Epoch 520/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3832\n",
      "Epoch 521/3000\n",
      "52/52 [==============================] - 6s 117ms/step - loss: 0.3936\n",
      "Epoch 522/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3955\n",
      "Epoch 523/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3866\n",
      "Epoch 524/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3903\n",
      "Epoch 525/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3921\n",
      "Epoch 526/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3940\n",
      "Epoch 527/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3830\n",
      "Epoch 528/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3902\n",
      "Epoch 529/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3853\n",
      "Epoch 530/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3953\n",
      "Epoch 531/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3867\n",
      "Epoch 532/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3864\n",
      "Epoch 533/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3945\n",
      "Epoch 534/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3879\n",
      "Epoch 535/3000\n",
      "52/52 [==============================] - 6s 117ms/step - loss: 0.3861\n",
      "Epoch 536/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3916\n",
      "Epoch 537/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3888\n",
      "Epoch 538/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3878\n",
      "Epoch 539/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3893\n",
      "Epoch 540/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3825\n",
      "Epoch 541/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3911\n",
      "Epoch 542/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3881\n",
      "Epoch 543/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3799\n",
      "Epoch 544/3000\n",
      "52/52 [==============================] - 6s 117ms/step - loss: 0.3879\n",
      "Epoch 545/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3833\n",
      "Epoch 546/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3921\n",
      "Epoch 547/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3819\n",
      "Epoch 548/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3888\n",
      "Epoch 549/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3921\n",
      "Epoch 550/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3926\n",
      "Epoch 551/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3863\n",
      "Epoch 552/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3931\n",
      "Epoch 553/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3863\n",
      "Epoch 554/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 6s 117ms/step - loss: 0.3976\n",
      "Epoch 555/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3945\n",
      "Epoch 556/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3846\n",
      "Epoch 557/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3898\n",
      "Epoch 558/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3925\n",
      "Epoch 559/3000\n",
      "52/52 [==============================] - 6s 117ms/step - loss: 0.3802\n",
      "Epoch 560/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3822\n",
      "Epoch 561/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3935\n",
      "Epoch 562/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3938\n",
      "Epoch 563/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3914\n",
      "Epoch 564/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3922\n",
      "Epoch 565/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3877\n",
      "Epoch 566/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3834\n",
      "Epoch 567/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3875\n",
      "Epoch 568/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3862\n",
      "Epoch 569/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3839\n",
      "Epoch 570/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3890\n",
      "Epoch 571/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3898\n",
      "Epoch 572/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3935\n",
      "Epoch 573/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3875\n",
      "Epoch 574/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3821\n",
      "Epoch 575/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3935\n",
      "Epoch 576/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3819\n",
      "Epoch 577/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3882\n",
      "Epoch 578/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3921\n",
      "Epoch 579/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3817\n",
      "Epoch 580/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3848\n",
      "Epoch 581/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3900\n",
      "Epoch 582/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3847\n",
      "Epoch 583/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3837\n",
      "Epoch 584/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3822\n",
      "Epoch 585/3000\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.3894\n",
      "Epoch 586/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3872\n",
      "Epoch 587/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3912\n",
      "Epoch 588/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3913\n",
      "Epoch 589/3000\n",
      "52/52 [==============================] - 6s 117ms/step - loss: 0.3874\n",
      "Epoch 590/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3822\n",
      "Epoch 591/3000\n",
      "52/52 [==============================] - 6s 120ms/step - loss: 0.3755\n",
      "Epoch 592/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3882\n",
      "Epoch 593/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3846\n",
      "Epoch 594/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3835\n",
      "Epoch 595/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3835\n",
      "Epoch 596/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3845\n",
      "Epoch 597/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3813\n",
      "Epoch 598/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3872\n",
      "Epoch 599/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3816\n",
      "Epoch 600/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3882\n",
      "Epoch 601/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3940\n",
      "Epoch 602/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3776\n",
      "Epoch 603/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3908\n",
      "Epoch 604/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3842\n",
      "Epoch 605/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3838\n",
      "Epoch 606/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3835\n",
      "Epoch 607/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3845\n",
      "Epoch 608/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3901\n",
      "Epoch 609/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3787\n",
      "Epoch 610/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3867\n",
      "Epoch 611/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3885\n",
      "Epoch 612/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3896\n",
      "Epoch 613/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3841\n",
      "Epoch 614/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3891\n",
      "Epoch 615/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3860\n",
      "Epoch 616/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3845\n",
      "Epoch 617/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3897\n",
      "Epoch 618/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3830\n",
      "Epoch 619/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3841\n",
      "Epoch 620/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3865\n",
      "Epoch 621/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3904\n",
      "Epoch 622/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3811\n",
      "Epoch 623/3000\n",
      "52/52 [==============================] - 6s 120ms/step - loss: 0.3743\n",
      "Epoch 624/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3794\n",
      "Epoch 625/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3883\n",
      "Epoch 626/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3883\n",
      "Epoch 627/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3846\n",
      "Epoch 628/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3861\n",
      "Epoch 629/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3852\n",
      "Epoch 630/3000\n",
      "52/52 [==============================] - 6s 118ms/step - loss: 0.3739\n",
      "Epoch 631/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3792\n",
      "Epoch 632/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3871\n",
      "Epoch 633/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3771\n",
      "Epoch 634/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3862\n",
      "Epoch 635/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3909\n",
      "Epoch 636/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3872\n",
      "Epoch 637/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3850\n",
      "Epoch 638/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3898\n",
      "Epoch 639/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3929\n",
      "Epoch 640/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3888\n",
      "Epoch 641/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3852\n",
      "Epoch 642/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3829\n",
      "Epoch 643/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3765\n",
      "Epoch 644/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3815\n",
      "Epoch 645/3000\n",
      "52/52 [==============================] - 6s 120ms/step - loss: 0.3788\n",
      "Epoch 646/3000\n",
      "52/52 [==============================] - 6s 117ms/step - loss: 0.3756\n",
      "Epoch 647/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3839\n",
      "Epoch 648/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3889\n",
      "Epoch 649/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3902\n",
      "Epoch 650/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3885\n",
      "Epoch 651/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3826\n",
      "Epoch 652/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3852\n",
      "Epoch 653/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3849\n",
      "Epoch 654/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3844\n",
      "Epoch 655/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3839\n",
      "Epoch 656/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3872\n",
      "Epoch 657/3000\n",
      "52/52 [==============================] - 6s 119ms/step - loss: 0.3735\n",
      "Epoch 658/3000\n",
      "52/52 [==============================] - 6s 118ms/step - loss: 0.3733\n",
      "Epoch 659/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3806\n",
      "Epoch 660/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3857\n",
      "Epoch 661/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3743\n",
      "Epoch 662/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3771\n",
      "Epoch 663/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3818\n",
      "Epoch 664/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3843\n",
      "Epoch 665/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3820\n",
      "Epoch 666/3000\n",
      "52/52 [==============================] - 6s 117ms/step - loss: 0.3872\n",
      "Epoch 667/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3803\n",
      "Epoch 668/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3875\n",
      "Epoch 669/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3805\n",
      "Epoch 670/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3812\n",
      "Epoch 671/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3844\n",
      "Epoch 672/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3875\n",
      "Epoch 673/3000\n",
      "52/52 [==============================] - 6s 118ms/step - loss: 0.3741\n",
      "Epoch 674/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3881\n",
      "Epoch 675/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3885\n",
      "Epoch 676/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3867\n",
      "Epoch 677/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3841\n",
      "Epoch 678/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3879\n",
      "Epoch 679/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3893\n",
      "Epoch 680/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3814\n",
      "Epoch 681/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3769\n",
      "Epoch 682/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3758\n",
      "Epoch 683/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3926\n",
      "Epoch 684/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3878\n",
      "Epoch 685/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3836\n",
      "Epoch 686/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3760\n",
      "Epoch 687/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3815\n",
      "Epoch 688/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3869\n",
      "Epoch 689/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3798\n",
      "Epoch 690/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3827\n",
      "Epoch 691/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3741\n",
      "Epoch 692/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3779\n",
      "Epoch 693/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3801\n",
      "Epoch 694/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3863\n",
      "Epoch 695/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3777\n",
      "Epoch 696/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3840\n",
      "Epoch 697/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3842\n",
      "Epoch 698/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3802\n",
      "Epoch 699/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3816\n",
      "Epoch 700/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3786\n",
      "Epoch 701/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3815\n",
      "Epoch 702/3000\n",
      "52/52 [==============================] - 6s 118ms/step - loss: 0.3762\n",
      "Epoch 703/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3760\n",
      "Epoch 704/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3822\n",
      "Epoch 705/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3836\n",
      "Epoch 706/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3878\n",
      "Epoch 707/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3856\n",
      "Epoch 708/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3885\n",
      "Epoch 709/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3856\n",
      "Epoch 710/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3756\n",
      "Epoch 711/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3853\n",
      "Epoch 712/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3875\n",
      "Epoch 713/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3812\n",
      "Epoch 714/3000\n",
      "52/52 [==============================] - 6s 113ms/step - loss: 0.3804\n",
      "Epoch 715/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3846\n",
      "Epoch 716/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3806\n",
      "Epoch 717/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3801\n",
      "Epoch 718/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3856\n",
      "Epoch 719/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3928\n",
      "Epoch 720/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3860\n",
      "Epoch 721/3000\n",
      "52/52 [==============================] - 6s 117ms/step - loss: 0.3882\n",
      "Epoch 722/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3853\n",
      "Epoch 723/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3849\n",
      "Epoch 724/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3852\n",
      "Epoch 725/3000\n",
      "52/52 [==============================] - 6s 118ms/step - loss: 0.3844\n",
      "Epoch 726/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3861\n",
      "Epoch 727/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3820\n",
      "Epoch 728/3000\n",
      "52/52 [==============================] - 6s 117ms/step - loss: 0.3773\n",
      "Epoch 729/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3876\n",
      "Epoch 730/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3821\n",
      "Epoch 731/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3833\n",
      "Epoch 732/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3782\n",
      "Epoch 733/3000\n",
      "52/52 [==============================] - 6s 117ms/step - loss: 0.3779\n",
      "Epoch 734/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3775\n",
      "Epoch 735/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3788\n",
      "Epoch 736/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3783\n",
      "Epoch 737/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3806\n",
      "Epoch 738/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3765\n",
      "Epoch 739/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3802\n",
      "Epoch 740/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3799\n",
      "Epoch 741/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3786\n",
      "Epoch 742/3000\n",
      "52/52 [==============================] - 6s 117ms/step - loss: 0.3822\n",
      "Epoch 743/3000\n",
      "52/52 [==============================] - 6s 117ms/step - loss: 0.3777\n",
      "Epoch 744/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3832\n",
      "Epoch 745/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3741\n",
      "Epoch 746/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3809\n",
      "Epoch 747/3000\n",
      "52/52 [==============================] - 6s 117ms/step - loss: 0.3775\n",
      "Epoch 748/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3839\n",
      "Epoch 749/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3852\n",
      "Epoch 750/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3807\n",
      "Epoch 751/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3788\n",
      "Epoch 752/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3900\n",
      "Epoch 753/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3882\n",
      "Epoch 754/3000\n",
      "52/52 [==============================] - 6s 117ms/step - loss: 0.3832\n",
      "Epoch 755/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3751\n",
      "Epoch 756/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3791\n",
      "Epoch 757/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3813\n",
      "Epoch 758/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3808\n",
      "Epoch 759/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3910\n",
      "Epoch 760/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3733\n",
      "Epoch 761/3000\n",
      "52/52 [==============================] - 6s 117ms/step - loss: 0.3776\n",
      "Epoch 762/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3800\n",
      "Epoch 763/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3840\n",
      "Epoch 764/3000\n",
      "52/52 [==============================] - 6s 117ms/step - loss: 0.3790\n",
      "Epoch 765/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3785\n",
      "Epoch 766/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3780\n",
      "Epoch 767/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3811\n",
      "Epoch 768/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3795\n",
      "Epoch 769/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3768\n",
      "Epoch 770/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3856\n",
      "Epoch 771/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3765\n",
      "Epoch 772/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3879\n",
      "Epoch 773/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3763\n",
      "Epoch 774/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3759\n",
      "Epoch 775/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3802\n",
      "Epoch 776/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3809\n",
      "Epoch 777/3000\n",
      "52/52 [==============================] - 6s 118ms/step - loss: 0.3724\n",
      "Epoch 778/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3816\n",
      "Epoch 779/3000\n",
      "52/52 [==============================] - 6s 117ms/step - loss: 0.3792\n",
      "Epoch 780/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3864\n",
      "Epoch 781/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3740\n",
      "Epoch 782/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3802\n",
      "Epoch 783/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3886\n",
      "Epoch 784/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3802\n",
      "Epoch 785/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3731\n",
      "Epoch 786/3000\n",
      "52/52 [==============================] - 6s 119ms/step - loss: 0.3710\n",
      "Epoch 787/3000\n",
      "52/52 [==============================] - 6s 118ms/step - loss: 0.3709\n",
      "Epoch 788/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3824\n",
      "Epoch 789/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3806\n",
      "Epoch 790/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3729\n",
      "Epoch 791/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3798\n",
      "Epoch 792/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3792\n",
      "Epoch 793/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3907\n",
      "Epoch 794/3000\n",
      "52/52 [==============================] - 6s 116ms/step - loss: 0.3753\n",
      "Epoch 795/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3744\n",
      "Epoch 796/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3838\n",
      "Epoch 797/3000\n",
      "52/52 [==============================] - 6s 117ms/step - loss: 0.3738\n",
      "Epoch 798/3000\n",
      "52/52 [==============================] - 6s 114ms/step - loss: 0.3881\n",
      "Epoch 799/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3835\n",
      "Epoch 800/3000\n",
      "52/52 [==============================] - 6s 117ms/step - loss: 0.3819\n",
      "Epoch 801/3000\n",
      "52/52 [==============================] - 6s 115ms/step - loss: 0.3810\n",
      "Epoch 802/3000\n",
      "29/52 [===============>..............] - ETA: 2s - loss: 0.3821"
     ]
    }
   ],
   "source": [
    "train_network(True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences_output(notes, pitchnames, n_vocab):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "    # map between notes and integers and back\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    sequence_length = 16\n",
    "    network_input = []\n",
    "    output = []\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        output.append(note_to_int[sequence_out])\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    normalized_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    # normalize input\n",
    "    normalized_input = normalized_input / float(n_vocab)\n",
    "\n",
    "    return (network_input, normalized_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_notes(model, network_input, pitchnames, n_vocab):\n",
    "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
    "    # pick a random sequence from the input as a starting point for the prediction\n",
    "    start = np.random.randint(0, len(network_input)-1)\n",
    "\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    pattern = network_input[start]\n",
    "    prediction_output = []\n",
    "\n",
    "    # generate 500 notes\n",
    "    for note_index in range(500):\n",
    "        prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        prediction_input = prediction_input / float(n_vocab)\n",
    "\n",
    "        prediction = model.predict(prediction_input, verbose=0)\n",
    "\n",
    "        index = np.random.choice(prediction.shape[1], p=(prediction[0] / sum(prediction[0])))\n",
    "        result = int_to_note[index]\n",
    "        prediction_output.append(result)\n",
    "\n",
    "        pattern.append(index)\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "\n",
    "    return prediction_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From: https://stackoverflow.com/questions/1806278/convert-fraction-to-float\n",
    "def convert_to_float(frac_str):\n",
    "    try:\n",
    "        return float(frac_str)\n",
    "    except ValueError:\n",
    "        num, denom = frac_str.split('/')\n",
    "        try:\n",
    "            leading, num = num.split(' ')\n",
    "            whole = float(leading)\n",
    "        except ValueError:\n",
    "            whole = 0\n",
    "        frac = float(num) / float(denom)\n",
    "        return whole - frac if whole < 0 else whole + frac\n",
    "\n",
    "def create_midi(prediction_output):\n",
    "    \"\"\" convert the output from the prediction to notes and create a midi file\n",
    "        from the notes \"\"\"\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        pattern = pattern.split()\n",
    "        temp = pattern[0]\n",
    "        duration = pattern[1]\n",
    "        pattern = temp\n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "        # pattern is a rest\n",
    "        elif('rest' in pattern):\n",
    "            new_rest = note.Rest(pattern)\n",
    "            new_rest.offset = offset\n",
    "            new_rest.storedInstrument = instrument.Piano() #???\n",
    "            output_notes.append(new_rest)\n",
    "        # pattern is a note\n",
    "        else:\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += convert_to_float(duration)\n",
    "\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "\n",
    "    midi_stream.write('midi', fp='test_output.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate():\n",
    "    \"\"\" Generate a piano midi file \"\"\"\n",
    "    #load the notes used to train the model\n",
    "    notes = pickle.load(open('data/notes.p', 'rb'))\n",
    "\n",
    "    # Get all pitch names\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    # Get all pitch names\n",
    "    n_vocab = len(set(notes))\n",
    "\n",
    "    network_input, normalized_input = prepare_sequences_output(notes, pitchnames, n_vocab)\n",
    "    model = load_model('weights.hdf5')\n",
    "    prediction_output = generate_notes(model, network_input, pitchnames, n_vocab)\n",
    "    create_midi(prediction_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
